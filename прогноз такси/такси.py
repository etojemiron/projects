# -*- coding: utf-8 -*-
"""четенькое_такси.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Eym-x2V_lct8MY_mqZ25a1kg8xJ8nQvO
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from catboost import CatBoostRegressor
from sklearn.ensemble import RandomForestRegressor
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller

df = pd.read_csv('/data/t.csv',index_col=[0],parse_dates=[0])

df.sort_index(inplace=True)

df = df.resample('1H').sum()

"""Загружаем данные, делаем ресемпл по часу."""

df.info()

df['num_orders'].isna().sum()

df.plot(figsize=(20,10))

"""Смотрим на график, ряд не стационарный, на лицо тренд в конце, увеличивающаяся дисперсия, выбросы."""

def make_features(df, max_lag, rolling_mean_size):
    df['hour'] = df.index.hour
    df['month'] = df.index.month
    df['day'] = df.index.day
    df['dayofweek'] = df.index.dayofweek
    
    for lag in max_lag:
        df['lag_{}'.format(lag)] = df['num_orders'].shift(lag)

    df['rolling_mean'] = df['num_orders'].shift().rolling(rolling_mean_size).mean()

make_features(df, [1,2,3,4,24,48], 12)
df = df.dropna()

"""Создаем функцию добавления признаков, применяем к нашим данным и удаляем пустые значения"""

df

df.corr()

"""Критичных корреляций нет)

Тест для проверки стационарности временных рядов

Нулевая гипотеза, что есть единичный корень и ряд нестационарный, альтернативная, что его нет и ряд стационарен.
"""

def df_test(x):
  dftest = adfuller(x,autolag='AIC')
  dfout = pd.Series(dftest[0:3],index=['Statistic','p-value','Lags'])
  for key, value in dftest[4].items():
    dfout['Max Value (%s)'%key] = value
  print(dfout)

df_test(df['num_orders'])

"""В нашем случае можно отвергнуть нулевую гипотезу. По тесту Дики-Фуллера p-value меньше 5%, в целом уже можно строить модели."""

train, test = train_test_split(df, shuffle=False, test_size=0.1)

train_features = train.drop('num_orders',axis=1)
train_target = train['num_orders']
test_features = test.drop('num_orders',axis=1)
test_target = test['num_orders']

"""Объединим обучение моделей с кросс валидацией для временных рядов в одну функцию."""

def cross_validation(features, target, model, cv, param = None):
  scores = []
  batch = int(np.floor(features.shape[0] / cv))
  for i in range(cv-1):
    train_features = features.iloc[0:(i+1)*batch]
    test_features = features.iloc[(i+1)*batch + 1:(i+1)*batch + batch]
    train_target = target.iloc[0:(i+1)*batch]
    test_target = target.iloc[(i+1)*batch + 1:(i+1)*batch + batch]

    if param != None:
      estimator = GridSearchCV(model, param, scoring='neg_mean_squared_error')
    else:
      estimator = model
    
    estimator.fit(train_features,train_target)

    if param != None:
      best_estimator = estimator.best_estimator_
    else:
      best_estimator = estimator

    predict = best_estimator.predict(test_features)

    score = mean_squared_error(test_target,predict)
    scores.append(score)
  print('RMSE модели с кросс валидацией:', np.sqrt(np.mean(scores)))
  best_estimator = estimator.fit(features,target)
  return best_estimator

"""Обучим модели линейной регрессии, леса и бустинга"""

lr = cross_validation(train_features,train_target, LinearRegression(), 4, None)

forest = cross_validation(train_features,train_target, RandomForestRegressor(), 4, param={'max_depth':range(2,5)})

cat = cross_validation(train_features,train_target, CatBoostRegressor(verbose=False), 4, param={'n_estimators':[100,500,1000], 'max_depth':range(2,5), 'learning_rate':[0.01, 0.05, 0.1]})

predict = lr.predict(test_features)
lr_error = np.sqrt(mean_squared_error(test_target,predict))
print('RMSE тестовой выборки линейной регрессии:',lr_error)

predict = forest.predict(test_features)
forest_error = np.sqrt(mean_squared_error(test_target,predict))
print('RMSE тестовой выборки леса:',forest_error)

predict = cat.predict(test_features)
cat_error = np.sqrt(mean_squared_error(test_target,predict))
print('RMSE тестовой выборки бустинга:',cat_error)

data = pd.DataFrame(columns=['result_test'],index=['LR','FOREST','CATBOOST'])
data['result_test'] = [lr_error,forest_error,cat_error]
print(data)

test_target.mean()

"""Полученные значения соберем в таблицу. 

По результатам лучше всего на тестовых значениях справляется справляется бустинг, второе место у линейной регрессии и 3й лес.
"""